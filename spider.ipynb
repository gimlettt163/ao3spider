{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65aa7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "html =\"\"\"\n",
    "<li id=\"work_54907306\" class=\"work blurb group work-54907306 user-21024895\" role=\"article\">\n",
    "\n",
    "<div class=\"header module\">\n",
    "<h4 class=\"heading\">\n",
    "<a href=\"/works/54907306\">【夏以昼×你】昼</a>\n",
    "by\n",
    "\n",
    "<a rel=\"author\" href=\"/users/Saka1010/pseuds/Saka1010\">Saka1010</a>\n",
    "</h4>\n",
    "<h5 class=\"fandoms heading\">\n",
    "<span class=\"landmark\">Fandoms:</span>\n",
    "<a class=\"tag\" href=\"/tags/%E6%81%8B%E4%B8%8E%E6%B7%B1%E7%A9%BA%20%7C%20Love%20and%20Deepspace%20(Video%20Game)/works\">恋与深空 | Love and Deepspace (Video Game)</a>\n",
    "&nbsp;\n",
    "</h5>\n",
    "\n",
    "<ul class=\"required-tags\">\n",
    "<li> <a class=\"help symbol question modal modal-attached\" title=\"Symbols key\" href=\"/help/symbols-key.html\" aria-controls=\"modal\"><span class=\"rating-mature rating\" title=\"Mature\"><span class=\"text\">Mature</span></span></a></li>\n",
    "<li> <a class=\"help symbol question modal modal-attached\" title=\"Symbols key\" href=\"/help/symbols-key.html\" aria-controls=\"modal\"><span class=\"warning-choosenotto warnings\" title=\"Choose Not To Use Archive Warnings\"><span class=\"text\">Choose Not To Use Archive Warnings</span></span></a></li>\n",
    "<li> <a class=\"help symbol question modal modal-attached\" title=\"Symbols key\" href=\"/help/symbols-key.html\" aria-controls=\"modal\"><span class=\"category-het category\" title=\"F/M\"><span class=\"text\">F/M</span></span></a></li>\n",
    "<li> <a class=\"help symbol question modal modal-attached\" title=\"Symbols key\" href=\"/help/symbols-key.html\" aria-controls=\"modal\"><span class=\"complete-yes iswip\" title=\"Complete Work\"><span class=\"text\">Complete Work</span></span></a></li>\n",
    "</ul>\n",
    "<p class=\"datetime\">02 Apr 2024</p>\n",
    "</div>\n",
    "\n",
    "<h6 class=\"landmark heading\">Tags</h6>\n",
    "<ul class=\"tags commas\">\n",
    "<li class=\"warnings\"><strong><a class=\"tag\" href=\"/tags/Choose%20Not%20To%20Use%20Archive%20Warnings/works\">Creator Chose Not To Use Archive Warnings</a></strong></li><li class=\"characters\"><a class=\"tag\" href=\"/tags/%E5%A4%8F%E4%BB%A5%E6%98%BC/works\">夏以昼</a></li> <li class=\"characters\"><a class=\"tag\" href=\"/tags/Xia%20Yizhou%20%7C%20Caleb/works\">Xia Yizhou | Caleb</a></li><li class=\"freeforms\"><a class=\"tag\" href=\"/tags/R18/works\">R18</a></li>\n",
    "</ul>\n",
    "\n",
    "<h6 class=\"landmark heading\">Summary</h6>\n",
    "<blockquote class=\"userstuff summary\">\n",
    "<p>你是他的白昼，他是你的夏以昼。</p><p>突然回归の夏以昼x自认单恋且迟钝の你</p><p>（天赋异禀哥x小魅魔妹）</p>\n",
    "</blockquote>\n",
    "\n",
    "<dl class=\"stats\">\n",
    "<dt class=\"language\">Language:</dt>\n",
    "<dd class=\"language\" lang=\"zh\">中文-普通话 國語</dd>\n",
    "<dt class=\"words\">Words:</dt>\n",
    "<dd class=\"words\">7,558</dd>\n",
    "<dt class=\"chapters\">Chapters:</dt>\n",
    "<dd class=\"chapters\">1/1</dd>\n",
    "<dt class=\"comments\">Comments:</dt>\n",
    "<dd class=\"comments\"><a href=\"/works/54907306?show_comments=true#comments\">7</a></dd>\n",
    "<dt class=\"kudos\">Kudos:</dt>\n",
    "<dd class=\"kudos\"><a href=\"/works/54907306#kudos\">159</a></dd>\n",
    "<dt class=\"bookmarks\">Bookmarks:</dt>\n",
    "<dd class=\"bookmarks\"><a href=\"/works/54907306/bookmarks\">6</a></dd>\n",
    "<dt class=\"hits\">Hits:</dt>\n",
    "<dd class=\"hits\">5,046</dd>\n",
    "</dl>\n",
    "</li>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff716f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a2693\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\bs4\\__init__.py:228: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html,\"html.parser\",from_encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdc31f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标题: 【夏以昼×你】昼\n",
      "作者: Saka1010\n"
     ]
    }
   ],
   "source": [
    "title_tag = soup.find('a')\n",
    "title = title_tag.get_text(strip=True) if title_tag else \"未找到标题\"\n",
    "\n",
    "# 找到作者的<a>标签并提取文本\n",
    "author_tag = soup.find('a', rel=\"author\")\n",
    "author = author_tag.get_text(strip=True) if author_tag else \"未找到作者\"\n",
    "\n",
    "print(\"标题:\", title)\n",
    "print(\"作者:\", author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d0f30e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'href' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m stats \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#\"标题\":soup.find('a',< href=\"/works/54907306\">【夏以昼×你】昼</a>),\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m标题\u001b[39m\u001b[38;5;124m\"\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[43mhref\u001b[49m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m评论\u001b[39m\u001b[38;5;124m\"\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m点赞\u001b[39m\u001b[38;5;124m\"\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkudos\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m收藏\u001b[39m\u001b[38;5;124m\"\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbookmarks\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m点击\u001b[39m\u001b[38;5;124m\"\u001b[39m: soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m统计信息:\u001b[39m\u001b[38;5;124m\"\u001b[39m, stats)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'href' is not defined"
     ]
    }
   ],
   "source": [
    "stats = {\n",
    "    #\"标题\":soup.find('a',< href=\"/works/54907306\">【夏以昼×你】昼</a>),\n",
    "    #\"标题\": soup.find('a', class_=href).get_text(strip=True),\n",
    "    \"评论\": soup.find('dd', class_='comments').get_text(strip=True),\n",
    "    \"点赞\": soup.find('dd', class_='kudos').get_text(strip=True),\n",
    "    \"收藏\": soup.find('dd', class_='bookmarks').get_text(strip=True),\n",
    "    \"点击\": soup.find('dd', class_='hits').get_text(strip=True)\n",
    "}\n",
    "print(\"统计信息:\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec4fd273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有的链接\n",
      "a http://example.com/elsie Elsie\n",
      "a http://example.com/lacie Lacie\n",
      "a http://example.com/tillie Tillie\n",
      "获取特定的URL地址\n",
      "a http://example.com/elsie ['sister'] Elsie\n",
      "正则表达式匹配\n",
      "a http://example.com/tillie ['sister'] Tillie\n",
      "获取P段落的文字\n",
      "p ['story'] Once upon a time there were three little sisters; and their names were\n",
      "Elsie,\n",
      "Lacie and\n",
      "Tillie;\n",
      "and they lived at the bottom of a well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a2693\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\bs4\\__init__.py:228: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    " \n",
    "import re\n",
    " \n",
    "from bs4 import BeautifulSoup\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "html=\"\"\"\n",
    "<div class=\"header module\">\n",
    "<h4 class=\"heading\">\n",
    "<a href=\"/works/54907306\">【夏以昼×你】昼</a>\n",
    "by\n",
    "\"\"\"\n",
    "#创建一个BeautifulSoup解析对象\n",
    "soup = BeautifulSoup(html_doc,\"html.parser\",from_encoding=\"utf-8\")\n",
    "#获取所有的链接\n",
    "links = soup.find_all('a')\n",
    "print(\"所有的链接\")\n",
    "for link in links:\n",
    "    print(link.name,link['href'],link.get_text())\n",
    " \n",
    "print(\"获取特定的URL地址\")\n",
    "link_node = soup.find('a',href=\"http://example.com/elsie\")\n",
    "print(link_node.name,link_node['href'],link_node['class'],link_node.get_text())\n",
    " \n",
    "print(\"正则表达式匹配\")\n",
    "link_node = soup.find('a',href=re.compile(r\"ti\"))\n",
    "print(link_node.name,link_node['href'],link_node['class'],link_node.get_text())\n",
    " \n",
    "print(\"获取P段落的文字\")\n",
    "p_node = soup.find('p',class_='story')\n",
    "print(p_node.name,p_node['class'],p_node.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38790bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # 正则表达式，进行文字匹配`\n",
    "import urllib.request, urllib.error  # 制定URL，获取网页数据\n",
    "#import xlwt  # 进行excel操作\n",
    "\n",
    "# 假设html_content是上述HTML代码的字符串\n",
    "html_content = \"\"\"\n",
    "<li id=\"work_54907306\" class=\"work blurb group work-54907306 user-21024895\" role=\"article\">\n",
    "...\n",
    "</li>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4c47b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标题: re.compile('<a href=\"/works/54907306\">(.*)</a>')\n"
     ]
    }
   ],
   "source": [
    "# 使用BeautifulSoup解析HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# 提取标题\n",
    "Title = re.compile(r'<a href=\"/works/54907306\">(.*)</a>')\n",
    "#title = soup.find('h4', class_='heading').get_text(strip=True)\n",
    "print(\"标题:\", Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05183115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 提取作者\n",
    "author = soup.find('a', rel='author').get_text(strip=True)\n",
    "print(\"作者:\", author)\n",
    "\n",
    "# 提取标签\n",
    "tags = [tag.get_text(strip=True) for tag in soup.find_all('a', class_='tag')]\n",
    "print(\"标签:\", tags)\n",
    "\n",
    "# 提取摘要\n",
    "summary = soup.find('blockquote', class_='userstuff summary').get_text(strip=True)\n",
    "print(\"摘要:\", summary)\n",
    "\n",
    "# 提取统计信息\n",
    "stats = {\n",
    "    \"语言\": soup.find('dd', class_='language').get_text(strip=True),\n",
    "    \"字数\": soup.find('dd', class_='words').get_text(strip=True),\n",
    "    \"章节\": soup.find('dd', class_='chapters').get_text(strip=True),\n",
    "    \"评论\": soup.find('dd', class_='comments').get_text(strip=True),\n",
    "    \"点赞\": soup.find('dd', class_='kudos').get_text(strip=True),\n",
    "    \"收藏\": soup.find('dd', class_='bookmarks').get_text(strip=True),\n",
    "    \"点击\": soup.find('dd', class_='hits').get_text(strip=True)\n",
    "}\n",
    "print(\"统计信息:\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "deb73407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askURL(url):\n",
    "    head = {  # 模拟浏览器头部信息，向豆瓣服务器发送消息\n",
    "        \"User-Agent\": \"Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 80.0.3987.122  Safari / 537.36\"\n",
    "    }\n",
    "    # 用户代理，表示告诉豆瓣服务器，我们是什么类型的机器、浏览器（本质上是告诉浏览器，我们可以接收什么水平的文件内容）\n",
    "\n",
    "    request = urllib.request.Request(url, headers=head)\n",
    "    html = \"\"\n",
    "    try:\n",
    "        response = urllib.request.urlopen(request)\n",
    "        html = response.read().decode(\"utf-8\")\n",
    "    except urllib.error.URLError as e:\n",
    "        if hasattr(e, \"code\"):\n",
    "            print(e.code)\n",
    "        if hasattr(e, \"reason\"):\n",
    "            print(e.reason)\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b570c46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n"
     ]
    }
   ],
   "source": [
    "url='https://archiveofourown.org/works/search?work_search%5Bquery%5D=%E5%A4%8F%E4%BB%A5%E6%98%BC'\n",
    "html = askURL(url)  # 保存获取到的网页源码\n",
    "# 2.逐一解析数据\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "for item in soup.find_all('li', role=\"article\"):\n",
    "    print(\"*******************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee90a591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "夏以昼\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import unquote\n",
    "\n",
    "# URL编码的字符串\n",
    "encoded_str = \"%E5%A4%8F%E4%BB%A5%E6%98%BC\"\n",
    "\n",
    "# 解码为中文\n",
    "decoded_str = unquote(encoded_str)\n",
    "\n",
    "print(decoded_str)  # 输出: 夏以昼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
